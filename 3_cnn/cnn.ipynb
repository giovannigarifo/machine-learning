{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "CrALtEY2PDwv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        "#### Giovanni Garifo - January 6, 2019\n",
        "\n",
        "The CIFAR100 dataset is composed of 100 classes containing 600 images each, the images have a resolution of 32x32 pixels in RGB format.  Of the 600 images for a given class, 500 are used as training set, and 100 as test set.\n",
        "\n",
        "We want to use different kinds of neural networks to classify the images in the test set."
      ]
    },
    {
      "metadata": {
        "id": "5dHqAXfhk_Ah",
        "colab_type": "code",
        "outputId": "e6e33d69-22fe-483b-f653-ade340db6300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -q http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gc1srYdSyFo7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# SELECT THE MODEL THAT YOU WANT TO TRAIN #\n",
        "###########################################\n",
        "\n",
        "'''\n",
        "NN: simple fully connected Neural Network\n",
        "CNN_1: first  CNN, with number of filters for each convolutional layer: 32/32/32/34\n",
        "CNN_2: second CNN, with number of filters for each convolutional layer: 128/128/128/256\n",
        "CNN_3: second CNN, with number of filters for each convolutional layer: 256/256/256/512\n",
        "CNN_4: second CNN, with number of filters for each convolutional layer: 512/512/512/1024\n",
        "CNN_5: it's CNN_2 with batch normalization after each convolution layer\n",
        "CNN_6: it's CNN_2 with batch normalization after each convolution layer, and FC1 wider (8192)\n",
        "CNN_7: it's CNN_2 with batch normalization after each convolution layer, and dropout 0.5 on FC1\n",
        "CNN_8: it's CNN_2 with data augmentation: random horizontal flip and random crop\n",
        "CNN_9: ResNet18 pre-trained over ImageNet, with only changes to the FC layer, training set with data augmentation\n",
        "'''\n",
        "MODEL = \"NN\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "erP5ZR96lFNR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToPILImage\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "24T6bvfnuXZ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####################\n",
        "# Define constants #\n",
        "####################\n",
        "\n",
        "NUM_CLASSES = 100\n",
        "NUM_EPOCHS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OXglbvM23-Ye",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#####################\n",
        "# Utility functions #\n",
        "#####################\n",
        "\n",
        "# function to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "    \n",
        "def plot_kernel(model):\n",
        "    model_weights = model.state_dict()\n",
        "    fig = plt.figure()\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for idx, filt  in enumerate(model_weights['conv1.weight']):\n",
        "    #print(filt[0, :, :])\n",
        "        if idx >= 32: continue\n",
        "        plt.subplot(4,8, idx + 1)\n",
        "        plt.imshow(filt[0, :, :], cmap=\"gray\")\n",
        "        plt.axis('off')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "def plot_kernel_output(model,images):\n",
        "    fig1 = plt.figure()\n",
        "    plt.figure(figsize=(1,1))\n",
        "    \n",
        "    img_normalized = (images[0] - images[0].min()) / (images[0].max() - images[0].min())\n",
        "    plt.imshow(img_normalized.numpy().transpose(1,2,0))\n",
        "    plt.show()\n",
        "    output = model.conv1(images)\n",
        "    layer_1 = output[0, :, :, :]\n",
        "    layer_1 = layer_1.data\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for idx, filt  in enumerate(layer_1):\n",
        "        if idx >= 32: continue\n",
        "        plt.subplot(4,8, idx + 1)\n",
        "        plt.imshow(filt, cmap=\"gray\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def plot_loss_accuracy_statistics(statistics):\n",
        "  \n",
        "  # plot loss\n",
        "  loss_values = np.array(statistics[:,0]).T \n",
        "  accuracy_values = np.array(statistics[:,1]).T\n",
        "  epochs_values = np.arange(NUM_EPOCHS)\n",
        "  \n",
        "  plt.figure(figsize=(12,4))\n",
        "  \n",
        "  plt.subplot(1, 2, 1)\n",
        " \n",
        " # plt.figure(1)\n",
        "  plt.plot(epochs_values, loss_values, label=\"Loss\")\n",
        "  plt.xticks(epochs_values)\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title(\"Loss behaviour\")\n",
        "  \n",
        "  plt.subplot(1, 2, 2)\n",
        "  #plt.figure(2)\n",
        "  plt.plot(epochs_values, accuracy_values, label=\"Accuracy\")\n",
        "  plt.xticks(epochs_values)\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.title(\"Accuracy behaviour\")\n",
        "\n",
        "  \n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-kUSQJPlNTy",
        "colab_type": "code",
        "outputId": "c7e5eee2-1eb8-47e9-bfe9-8aea576a806f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "######################\n",
        "# Dataset definition #\n",
        "######################\n",
        "\n",
        "#transform are heavily used to do simple and complex transformation and data augmentation\n",
        "\n",
        "if MODEL == \"CNN_8\":\n",
        "  transform_train = transforms.Compose(\n",
        "    [\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.Resize((40,40)),\n",
        "     transforms.RandomCrop((32,32)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "  transform_test = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((32,32)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "     ])\n",
        "elif MODEL == \"CNN_9\":\n",
        "  transform_train = transforms.Compose(\n",
        "    [\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.Resize((248,248)),\n",
        "     transforms.RandomCrop((224,224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "  transform_test = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((224,224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "     ])\n",
        "else:\n",
        "  transform_train = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((32,32)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "  transform_test = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((32,32)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "     ])\n",
        "  \n",
        "print(\"Tranformations used for training set: \\n\")\n",
        "print(transform_train)  \n",
        "\n",
        "print(\"Tranformations used for test set: \\n\")\n",
        "print(transform_test)\n",
        "  \n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=4,drop_last=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=4,drop_last=True)\n",
        "\n",
        "dataiter = iter(trainloader)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tranformations used for training set: \n",
            "\n",
            "Compose(\n",
            "    Resize(size=(32, 32), interpolation=PIL.Image.BILINEAR)\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            ")\n",
            "Tranformations used for test set: \n",
            "\n",
            "Compose(\n",
            "    Resize(size=(32, 32), interpolation=PIL.Image.BILINEAR)\n",
            "    ToTensor()\n",
            "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            ")\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QlncXx1wl8ZM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#################################\n",
        "# Define Neural Network classes #\n",
        "#################################\n",
        "\n",
        "class old_nn(nn.Module):\n",
        "    '''\n",
        "    Class that defines an old style fully connected network (multilayer perceptrons)    \n",
        "    '''\n",
        "    \n",
        "    # instantiate the neural network\n",
        "    def __init__(self):\n",
        "        super(old_nn, self).__init__()\n",
        "        \n",
        "        # First fully connected layer, perform a linear (z=w*x+b) transormation\n",
        "        self.fc1 = nn.Linear(32*32*3, # number of input features\n",
        "                             4096) # number of output features = number of neurons in first hidden layer\n",
        "        \n",
        "        # from first hidden layer to second hidden layer\n",
        "        self.fc2 = nn.Linear(4096, 4096) \n",
        "        \n",
        "        # from second hidden layer to output layer\n",
        "        self.fc3 = nn.Linear(4096, NUM_CLASSES)\n",
        "\n",
        "        \n",
        "    # Perform forward pass\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "      \n",
        "      \n",
        "\n",
        "class CNN_1234(nn.Module):\n",
        "    '''\n",
        "    Class that defines a Convolutional Neural Network\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN_1234, self).__init__()\n",
        "        #conv2d first parameter is the number of kernels at input (you get it from the output value of the previous layer)\n",
        "        #conv2d second parameter is the number of kernels you wanna have in your convolution, so it will be the n. of kernels at output.\n",
        "        #conv2d third, fourth and fifth parameters are, as you can read, kernel_size, stride and zero padding :)\n",
        "        \n",
        "        # OutputVolume formula: (inputWidth + 2*padding - kernelSize)/stride + 1\n",
        "        \n",
        "        # Input sample has size 32x32x3, first conv outputs 32 feature maps.\n",
        "        # output volume size: (32+2*0-5)/2+1 = 30 => 14*14*32\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=0)\n",
        "        \n",
        "        # output volume size of conv2: (14-3)+1 = 12 => 12*12*32\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
        "        \n",
        "        # output volume size of conv3: (12-3)+1 = 10 => 10*10*32\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0)\n",
        "        \n",
        "        # output volume size of conv_final: (10-3)+1 = 8 => 8*8*64\n",
        "        self.conv_final = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
        "        \n",
        "        # output volume size of pooling: (8-2)/2+1 = 4 => 4*4*64\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        self.fc1 = nn.Linear(4*4*64, 4096)\n",
        "        \n",
        "        self.fc2 = nn.Linear(4096, NUM_CLASSES) #last FC for classification \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.pool(self.conv_final(x)))\n",
        "        x = x.view(x.shape[0], -1) # needs reshape because fully connected layer take as input a row of values, not a volume!\n",
        "        x = F.relu(self.fc1(x))\n",
        "        #hint: dropout goes here!\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "      \n",
        "class CNN_567(nn.Module):\n",
        "    '''\n",
        "    Class that defines a Convolutional Neural Network\n",
        "    '''\n",
        "\n",
        "    def __init__(self, dropout_probability):\n",
        "        super(CNN_567, self).__init__()\n",
        "                     \n",
        "        self.conv1 = nn.Conv2d(3, 128, kernel_size=5, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv_final = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0)\n",
        "        \n",
        "        # here's why i've set second parameter to false: https://discuss.pytorch.org/t/performance-highly-degraded-when-eval-is-activated-in-the-test-phase/3323/15#post_16\n",
        "        self.bn = nn.BatchNorm2d(128, track_running_stats=False)     \n",
        "        self.bn_final = nn.BatchNorm2d(256, track_running_stats=False)\n",
        "    \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        self.fc1 = nn.Linear(4*4*256, 4096)\n",
        "        \n",
        "        self.dropout = nn.Dropout2d(dropout_probability) # if it's zero, no dropout happens\n",
        "        \n",
        "        self.fc2 = nn.Linear(4096, NUM_CLASSES) #last FC for classification \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn(self.conv1(x)))\n",
        "        x = F.relu(self.bn(self.conv2(x)))\n",
        "        x = F.relu(self.bn(self.conv3(x)))\n",
        "        x = F.relu(self.pool(self.bn_final(self.conv_final(x))))\n",
        "        x = x.view(x.shape[0], -1) # needs reshape because fully connected layer take as input a row of values, not a volume!\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XBFj2wJLw9gP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "# Define training and testing functions #\n",
        "#########################################\n",
        "\n",
        "def test_accuracy(net, dataloader):\n",
        "    '''\n",
        "    Testing phase, check accuracy over whole test test\n",
        "    '''\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net.eval() #important for deactivating dropout and correctly use batchnorm accumulated statistics\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "    \n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    accuracy = 100 * correct / total\n",
        "    print('Accuracy of the network on the test set: %d %%' % (accuracy))\n",
        "    return accuracy\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GCsi58IolyG-",
        "colab_type": "code",
        "outputId": "cd19e6cd-0af6-42c7-e647-565c8c83c9cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4022
        }
      },
      "cell_type": "code",
      "source": [
        "##############################\n",
        "# Train the selected network #\n",
        "##############################\n",
        "\n",
        "if MODEL == \"NN\":\n",
        "  net = old_nn()\n",
        "\n",
        "elif MODEL == \"CNN_1\":\n",
        "  net = CNN_1234()\n",
        "  \n",
        "elif MODEL == \"CNN_2\":\n",
        "  net = CNN_1234()\n",
        "  net.conv1 = nn.Conv2d(3, 128, kernel_size=5, stride=2, padding=0)\n",
        "  net.conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0)\n",
        "  net.conv3 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0)\n",
        "  net.conv_final = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0)\n",
        "  net.fc1 = nn.Linear(4*4*256, 4096)\n",
        "\n",
        "elif MODEL == \"CNN_3\":\n",
        "  net = CNN_1234()\n",
        "  net.conv1 = nn.Conv2d(3, 256, kernel_size=5, stride=2, padding=0)\n",
        "  net.conv2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=0)\n",
        "  net.conv3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=0)\n",
        "  net.conv_final = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=0)\n",
        "  net.fc1 = nn.Linear(4*4*512, 4096)\n",
        "\n",
        "elif MODEL == \"CNN_4\":\n",
        "  net = CNN_1234()\n",
        "  net.conv1 = nn.Conv2d(3, 512, kernel_size=5, stride=2, padding=0)\n",
        "  net.conv2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=0)\n",
        "  net.conv3 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=0)\n",
        "  net.conv_final = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=0)\n",
        "  net.fc1 = nn.Linear(4*4*1024, 4096)\n",
        "\n",
        "elif MODEL == \"CNN_5\":\n",
        "  net = CNN_567(0) #no dropout\n",
        "\n",
        "elif MODEL == \"CNN_6\":\n",
        "  net = CNN_567(0) #no dropout\n",
        "  net.fc1 = nn.Linear(4*4*256, 8192)        \n",
        "  net.fc2 = nn.Linear(8192, NUM_CLASSES)\n",
        "  \n",
        "elif MODEL == \"CNN_7\":\n",
        "  net = CNN_567(0.5) #dropout\n",
        "  \n",
        "elif MODEL == \"CNN_8\":\n",
        "  net = CNN_1234()\n",
        "  net.conv1 = nn.Conv2d(3, 128, kernel_size=5, stride=2, padding=0)\n",
        "  net.conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0)\n",
        "  net.conv3 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=0)\n",
        "  net.conv_final = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0)\n",
        "  net.fc1 = nn.Linear(4*4*256, 4096)\n",
        "\n",
        "elif MODEL == \"CNN_9\":\n",
        "  net = models.resnet18(pretrained=True)\n",
        "  net.fc = nn.Linear(512, NUM_CLASSES) #changing the fully connected layer of the already allocated network\n",
        "  \n",
        "  \n",
        "net = net.cuda() # use GPU\n",
        "\n",
        "# loss and accuracy statistics for each epoch\n",
        "epoch_loss_accuracy = np.zeros(shape=(NUM_EPOCHS,2)) \n",
        "\n",
        "# use negative log likelihood as criteria to calculate the loss,\n",
        "# it already does softmax computation for use!\n",
        "criterion = nn.CrossEntropyLoss().cuda() \n",
        "\n",
        "# Use Adam to do the parameters optimization,\n",
        "# better convergency w.r.t simple SGD :)\n",
        "learning_rate = 0.0001\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate) \n",
        "\n",
        "n_loss_print = len(trainloader)  #print every epoch, use smaller numbers if you wanna print loss more often!\n",
        "\n",
        "print(' - Starting Training of the model ' + MODEL + \" - \\n\") \n",
        "\n",
        "for epoch in range(NUM_EPOCHS):  # loop over the dataset NUM_EPOCHS times\n",
        "      \n",
        "    net.train() #important for activating dropout and correctly train batchnorm\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      # get the inputs and cast them into cuda wrapper\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.cuda()\n",
        "      labels = labels.cuda()\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      if i % n_loss_print == (n_loss_print -1):    \n",
        "          print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / n_loss_print))\n",
        "          # save and reset loss\n",
        "          epoch_loss_accuracy[epoch,0] = running_loss / n_loss_print\n",
        "          running_loss = 0.0\n",
        "      \n",
        "    # test the accuracy for this epoch\n",
        "    accuracy = test_accuracy(net,testloader)\n",
        "      \n",
        "    # save accuracy statistics\n",
        "    epoch_loss_accuracy[epoch,1] = accuracy\n",
        "    print(\"Statistics saved for epoch=%d: (loss=%.3f, accuracy=%d) \\n\" % (epoch, epoch_loss_accuracy[epoch,0], epoch_loss_accuracy[epoch,1]))\n",
        "  \n",
        "print(' - Finished Training of the model - ')\n",
        "\n",
        "  \n",
        "# plot statistics for the trained model\n",
        "plot_loss_accuracy_statistics(epoch_loss_accuracy)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " - Starting Training of the model NN - \n",
            "\n",
            "[1,   390] loss: 4.121\n",
            "Accuracy of the network on the test set: 11 %\n",
            "Statistics saved for epoch=0: (loss=4.121, accuracy=11) \n",
            "\n",
            "[2,   390] loss: 3.698\n",
            "Accuracy of the network on the test set: 15 %\n",
            "Statistics saved for epoch=1: (loss=3.698, accuracy=15) \n",
            "\n",
            "[3,   390] loss: 3.534\n",
            "Accuracy of the network on the test set: 17 %\n",
            "Statistics saved for epoch=2: (loss=3.534, accuracy=17) \n",
            "\n",
            "[4,   390] loss: 3.412\n",
            "Accuracy of the network on the test set: 19 %\n",
            "Statistics saved for epoch=3: (loss=3.412, accuracy=19) \n",
            "\n",
            "[5,   390] loss: 3.309\n",
            "Accuracy of the network on the test set: 20 %\n",
            "Statistics saved for epoch=4: (loss=3.309, accuracy=20) \n",
            "\n",
            "[6,   390] loss: 3.216\n",
            "Accuracy of the network on the test set: 21 %\n",
            "Statistics saved for epoch=5: (loss=3.216, accuracy=21) \n",
            "\n",
            "[7,   390] loss: 3.135\n",
            "Accuracy of the network on the test set: 22 %\n",
            "Statistics saved for epoch=6: (loss=3.135, accuracy=22) \n",
            "\n",
            "[8,   390] loss: 3.063\n",
            "Accuracy of the network on the test set: 23 %\n",
            "Statistics saved for epoch=7: (loss=3.063, accuracy=23) \n",
            "\n",
            "[9,   390] loss: 2.994\n",
            "Accuracy of the network on the test set: 23 %\n",
            "Statistics saved for epoch=8: (loss=2.994, accuracy=23) \n",
            "\n",
            "[10,   390] loss: 2.930\n",
            "Accuracy of the network on the test set: 24 %\n",
            "Statistics saved for epoch=9: (loss=2.930, accuracy=24) \n",
            "\n",
            "[11,   390] loss: 2.872\n",
            "Accuracy of the network on the test set: 24 %\n",
            "Statistics saved for epoch=10: (loss=2.872, accuracy=24) \n",
            "\n",
            "[12,   390] loss: 2.813\n",
            "Accuracy of the network on the test set: 25 %\n",
            "Statistics saved for epoch=11: (loss=2.813, accuracy=25) \n",
            "\n",
            "[13,   390] loss: 2.756\n",
            "Accuracy of the network on the test set: 26 %\n",
            "Statistics saved for epoch=12: (loss=2.756, accuracy=26) \n",
            "\n",
            "[14,   390] loss: 2.700\n",
            "Accuracy of the network on the test set: 26 %\n",
            "Statistics saved for epoch=13: (loss=2.700, accuracy=26) \n",
            "\n",
            "[15,   390] loss: 2.647\n",
            "Accuracy of the network on the test set: 26 %\n",
            "Statistics saved for epoch=14: (loss=2.647, accuracy=26) \n",
            "\n",
            "[16,   390] loss: 2.591\n",
            "Accuracy of the network on the test set: 27 %\n",
            "Statistics saved for epoch=15: (loss=2.591, accuracy=27) \n",
            "\n",
            "[17,   390] loss: 2.536\n",
            "Accuracy of the network on the test set: 27 %\n",
            "Statistics saved for epoch=16: (loss=2.536, accuracy=27) \n",
            "\n",
            "[18,   390] loss: 2.482\n",
            "Accuracy of the network on the test set: 27 %\n",
            "Statistics saved for epoch=17: (loss=2.482, accuracy=27) \n",
            "\n",
            "[19,   390] loss: 2.429\n",
            "Accuracy of the network on the test set: 28 %\n",
            "Statistics saved for epoch=18: (loss=2.429, accuracy=28) \n",
            "\n",
            "[20,   390] loss: 2.373\n",
            "Accuracy of the network on the test set: 28 %\n",
            "Statistics saved for epoch=19: (loss=2.373, accuracy=28) \n",
            "\n",
            "[21,   390] loss: 2.319\n",
            "Accuracy of the network on the test set: 28 %\n",
            "Statistics saved for epoch=20: (loss=2.319, accuracy=28) \n",
            "\n",
            "[22,   390] loss: 2.263\n",
            "Accuracy of the network on the test set: 29 %\n",
            "Statistics saved for epoch=21: (loss=2.263, accuracy=29) \n",
            "\n",
            "[23,   390] loss: 2.207\n",
            "Accuracy of the network on the test set: 28 %\n",
            "Statistics saved for epoch=22: (loss=2.207, accuracy=28) \n",
            "\n",
            "[24,   390] loss: 2.150\n",
            "Accuracy of the network on the test set: 29 %\n",
            "Statistics saved for epoch=23: (loss=2.150, accuracy=29) \n",
            "\n",
            "[25,   390] loss: 2.093\n",
            "Accuracy of the network on the test set: 29 %\n",
            "Statistics saved for epoch=24: (loss=2.093, accuracy=29) \n",
            "\n",
            "[26,   390] loss: 2.036\n",
            "Accuracy of the network on the test set: 29 %\n",
            "Statistics saved for epoch=25: (loss=2.036, accuracy=29) \n",
            "\n",
            "[27,   390] loss: 1.978\n",
            "Accuracy of the network on the test set: 29 %\n",
            "Statistics saved for epoch=26: (loss=1.978, accuracy=29) \n",
            "\n",
            "[28,   390] loss: 1.918\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=27: (loss=1.918, accuracy=30) \n",
            "\n",
            "[29,   390] loss: 1.857\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=28: (loss=1.857, accuracy=30) \n",
            "\n",
            "[30,   390] loss: 1.796\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=29: (loss=1.796, accuracy=30) \n",
            "\n",
            "[31,   390] loss: 1.735\n",
            "Accuracy of the network on the test set: 29 %\n",
            "Statistics saved for epoch=30: (loss=1.735, accuracy=29) \n",
            "\n",
            "[32,   390] loss: 1.673\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=31: (loss=1.673, accuracy=30) \n",
            "\n",
            "[33,   390] loss: 1.610\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=32: (loss=1.610, accuracy=30) \n",
            "\n",
            "[34,   390] loss: 1.549\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=33: (loss=1.549, accuracy=30) \n",
            "\n",
            "[35,   390] loss: 1.486\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=34: (loss=1.486, accuracy=30) \n",
            "\n",
            "[36,   390] loss: 1.419\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=35: (loss=1.419, accuracy=30) \n",
            "\n",
            "[37,   390] loss: 1.358\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=36: (loss=1.358, accuracy=30) \n",
            "\n",
            "[38,   390] loss: 1.294\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=37: (loss=1.294, accuracy=30) \n",
            "\n",
            "[39,   390] loss: 1.230\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=38: (loss=1.230, accuracy=30) \n",
            "\n",
            "[40,   390] loss: 1.169\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=39: (loss=1.169, accuracy=30) \n",
            "\n",
            "[41,   390] loss: 1.102\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=40: (loss=1.102, accuracy=30) \n",
            "\n",
            "[42,   390] loss: 1.041\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=41: (loss=1.041, accuracy=30) \n",
            "\n",
            "[43,   390] loss: 0.980\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=42: (loss=0.980, accuracy=30) \n",
            "\n",
            "[44,   390] loss: 0.919\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=43: (loss=0.919, accuracy=30) \n",
            "\n",
            "[45,   390] loss: 0.857\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=44: (loss=0.857, accuracy=30) \n",
            "\n",
            "[46,   390] loss: 0.801\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=45: (loss=0.801, accuracy=30) \n",
            "\n",
            "[47,   390] loss: 0.744\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=46: (loss=0.744, accuracy=30) \n",
            "\n",
            "[48,   390] loss: 0.689\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=47: (loss=0.689, accuracy=30) \n",
            "\n",
            "[49,   390] loss: 0.635\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=48: (loss=0.635, accuracy=30) \n",
            "\n",
            "[50,   390] loss: 0.586\n",
            "Accuracy of the network on the test set: 30 %\n",
            "Statistics saved for epoch=49: (loss=0.586, accuracy=30) \n",
            "\n",
            " - Finished Training of the model - \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs4AAAEVCAYAAADw/WNdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzlgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f05be149860>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}